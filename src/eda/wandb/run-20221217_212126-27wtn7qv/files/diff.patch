diff --git a/.DS_Store b/.DS_Store
index 8f1f1ca..1cc499b 100644
Binary files a/.DS_Store and b/.DS_Store differ
diff --git a/.spyproject/config/backups/workspace.ini.bak b/.spyproject/config/backups/workspace.ini.bak
index 9321b9f..e1794ff 100644
--- a/.spyproject/config/backups/workspace.ini.bak
+++ b/.spyproject/config/backups/workspace.ini.bak
@@ -4,7 +4,7 @@ save_data_on_exit = True
 save_history = True
 save_non_project_files = False
 project_type = 'empty-project-type'
-recent_files = ['main.py', 'MLproject', 'config.yaml', 'conda.yml']
+recent_files = ['src/train_random_forest/run.py']
 
 [main]
 version = 0.2.0
diff --git a/.spyproject/config/workspace.ini b/.spyproject/config/workspace.ini
index 9321b9f..e1794ff 100644
--- a/.spyproject/config/workspace.ini
+++ b/.spyproject/config/workspace.ini
@@ -4,7 +4,7 @@ save_data_on_exit = True
 save_history = True
 save_non_project_files = False
 project_type = 'empty-project-type'
-recent_files = ['main.py', 'MLproject', 'config.yaml', 'conda.yml']
+recent_files = ['src/train_random_forest/run.py']
 
 [main]
 version = 0.2.0
diff --git a/main.py b/main.py
index 2de300a..9a91382 100644
--- a/main.py
+++ b/main.py
@@ -1,28 +1,31 @@
+# =============================================================================
+# IMPORT MODULES
+# =============================================================================
 import json
-
 import mlflow
 import tempfile
 import os
-import wandb
 import hydra
 from omegaconf import DictConfig
 
+# =============================================================================
+# PIPELINE STEPS
+# =============================================================================
 _steps = [
     "download",
     "basic_cleaning",
     "data_check",
     "data_split",
     "train_random_forest",
-    # NOTE: We do not include this in the steps so it is not run by mistake.
-    # You first need to promote a model export to "prod" before you can run this,
-    # then you need to run this step explicitly
-    #    "test_regression_model"
+    "test_regression_model"
 ]
-
 # aliases
 join = os.path.join
 
 
+# =============================================================================
+# MAIN: HYDRA LINKS THE INDIVIDUAL MLFLOW COMPONENTS
+# =============================================================================
 # This automatically reads in the configuration
 @hydra.main(config_name='config')
 def go(config: DictConfig):
@@ -102,16 +105,12 @@ def go(config: DictConfig):
 
         if "train_random_forest" in active_steps:
 
-            # NOTE: we need to serialize the random forest configuration into JSON
             rf_config = os.path.abspath("rf_config.json")
             with open(rf_config, "w+") as fp:
                 # DO NOT TOUCH
                 json.dump(
                     dict(config["modeling"]["random_forest"].items()), fp)
 
-            # NOTE: use the rf_config we just created as the rf_config parameter for the train_random_forest
-            # step
-
             _ = mlflow.run(
                 os.path.join(root_dir, "src", "train_random_forest"),
                 "main",
@@ -137,5 +136,8 @@ def go(config: DictConfig):
             )
 
 
+# =============================================================================
+# CALL THE MAIN
+# =============================================================================
 if __name__ == "__main__":
     go()
diff --git a/src/basic_cleaning/run.py b/src/basic_cleaning/run.py
index 8a98c65..5cef18a 100644
--- a/src/basic_cleaning/run.py
+++ b/src/basic_cleaning/run.py
@@ -2,6 +2,9 @@
 """
 Download from W&B the raw dataset and apply some basic data cleaning, exporting the result to a new artifact
 """
+# =============================================================================
+# IMPORT MODULES
+# =============================================================================
 import argparse
 import logging
 import tempfile
@@ -60,6 +63,9 @@ def go(args):
     artifact.wait()
 
 
+# =============================================================================
+# CALL MAIN
+# =============================================================================
 if __name__ == "__main__":
 
     parser = argparse.ArgumentParser(description="A very basic data cleaning")
diff --git a/src/data_check/test_data.py b/src/data_check/test_data.py
index 1f4a37a..cc2c2c9 100644
--- a/src/data_check/test_data.py
+++ b/src/data_check/test_data.py
@@ -1,3 +1,6 @@
+# =============================================================================
+# IMPORT MODULES
+# =============================================================================
 import pandas as pd
 import numpy as np
 import scipy.stats
diff --git a/src/eda/EDA.ipynb b/src/eda/EDA.ipynb
index c4a1590..67ef732 100644
--- a/src/eda/EDA.ipynb
+++ b/src/eda/EDA.ipynb
@@ -5,11 +5,42 @@
    "execution_count": 1,
    "id": "70cf8037",
    "metadata": {},
-   "outputs": [],
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "/Users/christoszacharopoulos/anaconda3/envs/mlflow-2e7b179c2d499d61e01a8f7eb7cdf193dea44df9/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
+      "  from .autonotebook import tqdm as notebook_tqdm\n"
+     ]
+    },
+    {
+     "ename": "ImportError",
+     "evalue": "cannot import name 'DataError' from 'pandas.core.base' (/Users/christoszacharopoulos/anaconda3/envs/mlflow-2e7b179c2d499d61e01a8f7eb7cdf193dea44df9/lib/python3.10/site-packages/pandas/core/base.py)",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
+      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompose\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n",
+      "File \u001b[0;32m~/anaconda3/envs/mlflow-2e7b179c2d499d61e01a8f7eb7cdf193dea44df9/lib/python3.10/site-packages/pandas_profiling/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Main module of pandas-profiling.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m.. include:: ../../README.md\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontroller\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pandas_decorator\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprofile_report\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n",
+      "File \u001b[0;32m~/anaconda3/envs/mlflow-2e7b179c2d499d61e01a8f7eb7cdf193dea44df9/lib/python3.10/site-packages/pandas_profiling/controller/pandas_decorator.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"This file add the decorator on the DataFrame object.\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprofile_report\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprofile_report\u001b[39m(df: DataFrame, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ProfileReport:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124;03m\"\"\"Profile a DataFrame.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m        A ProfileReport of the DataFrame.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
+      "File \u001b[0;32m~/anaconda3/envs/mlflow-2e7b179c2d499d61e01a8f7eb7cdf193dea44df9/lib/python3.10/site-packages/pandas_profiling/profile_report.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config, Settings\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpectations_report\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExpectationsReport\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malerts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AlertType\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdescribe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m describe \u001b[38;5;28;01mas\u001b[39;00m describe_df\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msample\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sample\n",
+      "File \u001b[0;32m~/anaconda3/envs/mlflow-2e7b179c2d499d61e01a8f7eb7cdf193dea44df9/lib/python3.10/site-packages/pandas_profiling/model/alerts.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Settings\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorrelations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m perform_check_correlation\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@unique\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAlertType\u001b[39;00m(Enum):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124;03m\"\"\"Alert types\"\"\"\u001b[39;00m\n",
+      "File \u001b[0;32m~/anaconda3/envs/mlflow-2e7b179c2d499d61e01a8f7eb7cdf193dea44df9/lib/python3.10/site-packages/pandas_profiling/model/correlations.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultimethod\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multimethod\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataError\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Settings\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCorrelation\u001b[39;00m:\n",
+      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DataError' from 'pandas.core.base' (/Users/christoszacharopoulos/anaconda3/envs/mlflow-2e7b179c2d499d61e01a8f7eb7cdf193dea44df9/lib/python3.10/site-packages/pandas/core/base.py)"
+     ]
+    }
+   ],
    "source": [
+    "# =============================================================================\n",
+    "# MODULES\n",
+    "# =============================================================================\n",
     "import wandb\n",
     "import pandas as pd\n",
-    "import pandas_profiling"
+    "import pandas_profiling\n",
+    "import matplotlib.pyplot as plt\n",
+    "from sklearn.compose import ColumnTransformer\n",
+    "from sklearn.compose import make_column_selector as selector"
    ]
   },
   {
@@ -22,38 +53,10 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": null,
    "id": "9de6c414",
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mphyruz\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
-     ]
-    },
-    {
-     "data": {
-      "text/html": [
-       "\n",
-       "                Tracking run with wandb version 0.10.31<br/>\n",
-       "                Syncing run <strong style=\"color:#cdcd00\">distinctive-feather-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
-       "                Project page: <a href=\"https://wandb.ai/phyruz/nyc_airbnb\" target=\"_blank\">https://wandb.ai/phyruz/nyc_airbnb</a><br/>\n",
-       "                Run page: <a href=\"https://wandb.ai/phyruz/nyc_airbnb/runs/1litidi2\" target=\"_blank\">https://wandb.ai/phyruz/nyc_airbnb/runs/1litidi2</a><br/>\n",
-       "                Run data is saved locally in <code>/Users/scionti.eugenio/Desktop/Eugenio/Personal Development/Self-learning/Udacity/ML DevOps Engineer/udacity-mldevops/build_an_ml_pipeline_for_short_term_rental_prices_in_nyc/nd0821-c2-build-model-workflow-starter/src/eda/wandb/run-20220401_141750-1litidi2</code><br/><br/>\n",
-       "            "
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    }
-   ],
+   "outputs": [],
    "source": [
     "run = wandb.init(project='nyc_airbnb',\n",
     "                group='eda',\n",
@@ -62,197 +65,13 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": null,
    "id": "6bc4e227",
    "metadata": {},
    "outputs": [],
    "source": [
     "local_path = wandb.use_artifact('sample.csv:latest').file()\n",
-    "df = pd.read_csv(local_path)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 4,
-   "id": "ae1af5de",
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/html": [
-       "<div>\n",
-       "<style scoped>\n",
-       "    .dataframe tbody tr th:only-of-type {\n",
-       "        vertical-align: middle;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe tbody tr th {\n",
-       "        vertical-align: top;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe thead th {\n",
-       "        text-align: right;\n",
-       "    }\n",
-       "</style>\n",
-       "<table border=\"1\" class=\"dataframe\">\n",
-       "  <thead>\n",
-       "    <tr style=\"text-align: right;\">\n",
-       "      <th></th>\n",
-       "      <th>id</th>\n",
-       "      <th>name</th>\n",
-       "      <th>host_id</th>\n",
-       "      <th>host_name</th>\n",
-       "      <th>neighbourhood_group</th>\n",
-       "      <th>neighbourhood</th>\n",
-       "      <th>latitude</th>\n",
-       "      <th>longitude</th>\n",
-       "      <th>room_type</th>\n",
-       "      <th>price</th>\n",
-       "      <th>minimum_nights</th>\n",
-       "      <th>number_of_reviews</th>\n",
-       "      <th>last_review</th>\n",
-       "      <th>reviews_per_month</th>\n",
-       "      <th>calculated_host_listings_count</th>\n",
-       "      <th>availability_365</th>\n",
-       "    </tr>\n",
-       "  </thead>\n",
-       "  <tbody>\n",
-       "    <tr>\n",
-       "      <th>0</th>\n",
-       "      <td>9138664</td>\n",
-       "      <td>Private Lg Room 15 min to Manhattan</td>\n",
-       "      <td>47594947</td>\n",
-       "      <td>Iris</td>\n",
-       "      <td>Queens</td>\n",
-       "      <td>Sunnyside</td>\n",
-       "      <td>40.74271</td>\n",
-       "      <td>-73.92493</td>\n",
-       "      <td>Private room</td>\n",
-       "      <td>74</td>\n",
-       "      <td>2</td>\n",
-       "      <td>6</td>\n",
-       "      <td>2019-05-26</td>\n",
-       "      <td>0.13</td>\n",
-       "      <td>1</td>\n",
-       "      <td>5</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>1</th>\n",
-       "      <td>31444015</td>\n",
-       "      <td>TIME SQUARE CHARMING ONE BED IN HELL'S KITCHEN...</td>\n",
-       "      <td>8523790</td>\n",
-       "      <td>Johlex</td>\n",
-       "      <td>Manhattan</td>\n",
-       "      <td>Hell's Kitchen</td>\n",
-       "      <td>40.76682</td>\n",
-       "      <td>-73.98878</td>\n",
-       "      <td>Entire home/apt</td>\n",
-       "      <td>170</td>\n",
-       "      <td>3</td>\n",
-       "      <td>0</td>\n",
-       "      <td>NaN</td>\n",
-       "      <td>NaN</td>\n",
-       "      <td>1</td>\n",
-       "      <td>188</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>2</th>\n",
-       "      <td>8741020</td>\n",
-       "      <td>Voted #1 Location Quintessential 1BR W Village...</td>\n",
-       "      <td>45854238</td>\n",
-       "      <td>John</td>\n",
-       "      <td>Manhattan</td>\n",
-       "      <td>West Village</td>\n",
-       "      <td>40.73631</td>\n",
-       "      <td>-74.00611</td>\n",
-       "      <td>Entire home/apt</td>\n",
-       "      <td>245</td>\n",
-       "      <td>3</td>\n",
-       "      <td>51</td>\n",
-       "      <td>2018-09-19</td>\n",
-       "      <td>1.12</td>\n",
-       "      <td>1</td>\n",
-       "      <td>0</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>3</th>\n",
-       "      <td>34602077</td>\n",
-       "      <td>Spacious 1 bedroom apartment 15min from Manhattan</td>\n",
-       "      <td>261055465</td>\n",
-       "      <td>Regan</td>\n",
-       "      <td>Queens</td>\n",
-       "      <td>Astoria</td>\n",
-       "      <td>40.76424</td>\n",
-       "      <td>-73.92351</td>\n",
-       "      <td>Entire home/apt</td>\n",
-       "      <td>125</td>\n",
-       "      <td>3</td>\n",
-       "      <td>1</td>\n",
-       "      <td>2019-05-24</td>\n",
-       "      <td>0.65</td>\n",
-       "      <td>1</td>\n",
-       "      <td>13</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>4</th>\n",
-       "      <td>23203149</td>\n",
-       "      <td>Big beautiful bedroom in huge Bushwick apartment</td>\n",
-       "      <td>143460</td>\n",
-       "      <td>Megan</td>\n",
-       "      <td>Brooklyn</td>\n",
-       "      <td>Bushwick</td>\n",
-       "      <td>40.69839</td>\n",
-       "      <td>-73.92044</td>\n",
-       "      <td>Private room</td>\n",
-       "      <td>65</td>\n",
-       "      <td>2</td>\n",
-       "      <td>8</td>\n",
-       "      <td>2019-06-23</td>\n",
-       "      <td>0.52</td>\n",
-       "      <td>2</td>\n",
-       "      <td>8</td>\n",
-       "    </tr>\n",
-       "  </tbody>\n",
-       "</table>\n",
-       "</div>"
-      ],
-      "text/plain": [
-       "         id                                               name    host_id  \\\n",
-       "0   9138664                Private Lg Room 15 min to Manhattan   47594947   \n",
-       "1  31444015  TIME SQUARE CHARMING ONE BED IN HELL'S KITCHEN...    8523790   \n",
-       "2   8741020  Voted #1 Location Quintessential 1BR W Village...   45854238   \n",
-       "3  34602077  Spacious 1 bedroom apartment 15min from Manhattan  261055465   \n",
-       "4  23203149   Big beautiful bedroom in huge Bushwick apartment     143460   \n",
-       "\n",
-       "  host_name neighbourhood_group   neighbourhood  latitude  longitude  \\\n",
-       "0      Iris              Queens       Sunnyside  40.74271  -73.92493   \n",
-       "1    Johlex           Manhattan  Hell's Kitchen  40.76682  -73.98878   \n",
-       "2      John           Manhattan    West Village  40.73631  -74.00611   \n",
-       "3     Regan              Queens         Astoria  40.76424  -73.92351   \n",
-       "4     Megan            Brooklyn        Bushwick  40.69839  -73.92044   \n",
-       "\n",
-       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
-       "0     Private room     74               2                  6  2019-05-26   \n",
-       "1  Entire home/apt    170               3                  0         NaN   \n",
-       "2  Entire home/apt    245               3                 51  2018-09-19   \n",
-       "3  Entire home/apt    125               3                  1  2019-05-24   \n",
-       "4     Private room     65               2                  8  2019-06-23   \n",
-       "\n",
-       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
-       "0               0.13                               1                 5  \n",
-       "1                NaN                               1               188  \n",
-       "2               1.12                               1                 0  \n",
-       "3               0.65                               1                13  \n",
-       "4               0.52                               2                 8  "
-      ]
-     },
-     "execution_count": 4,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "df.head(5)"
+    "df = pd.read_csv(local_path) "
    ]
   },
   {
@@ -260,507 +79,109 @@
    "id": "ae4f1317",
    "metadata": {},
    "source": [
-    "### General information about the sample"
+    "### Dataset structure and general information"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": null,
    "id": "b3137c53",
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "<class 'pandas.core.frame.DataFrame'>\n",
-      "RangeIndex: 20000 entries, 0 to 19999\n",
-      "Data columns (total 16 columns):\n",
-      " #   Column                          Non-Null Count  Dtype  \n",
-      "---  ------                          --------------  -----  \n",
-      " 0   id                              20000 non-null  int64  \n",
-      " 1   name                            19993 non-null  object \n",
-      " 2   host_id                         20000 non-null  int64  \n",
-      " 3   host_name                       19992 non-null  object \n",
-      " 4   neighbourhood_group             20000 non-null  object \n",
-      " 5   neighbourhood                   20000 non-null  object \n",
-      " 6   latitude                        20000 non-null  float64\n",
-      " 7   longitude                       20000 non-null  float64\n",
-      " 8   room_type                       20000 non-null  object \n",
-      " 9   price                           20000 non-null  int64  \n",
-      " 10  minimum_nights                  20000 non-null  int64  \n",
-      " 11  number_of_reviews               20000 non-null  int64  \n",
-      " 12  last_review                     15877 non-null  object \n",
-      " 13  reviews_per_month               15877 non-null  float64\n",
-      " 14  calculated_host_listings_count  20000 non-null  int64  \n",
-      " 15  availability_365                20000 non-null  int64  \n",
-      "dtypes: float64(3), int64(7), object(6)\n",
-      "memory usage: 2.4+ MB\n"
-     ]
-    }
-   ],
-   "source": [
-    "df.info()"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 6,
-   "id": "d1dbdb44",
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "id                                20000\n",
-       "name                              19768\n",
-       "host_id                           17027\n",
-       "host_name                          6517\n",
-       "neighbourhood_group                   5\n",
-       "neighbourhood                       217\n",
-       "latitude                          12439\n",
-       "longitude                         10181\n",
-       "room_type                             3\n",
-       "price                               544\n",
-       "minimum_nights                       75\n",
-       "number_of_reviews                   323\n",
-       "last_review                        1507\n",
-       "reviews_per_month                   790\n",
-       "calculated_host_listings_count       47\n",
-       "availability_365                    366\n",
-       "dtype: int64"
-      ]
-     },
-     "execution_count": 6,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
-    "df.nunique()"
+    "print(df.head(5))"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 7,
-   "id": "79f0555e",
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "id                                   0\n",
-       "name                                 7\n",
-       "host_id                              0\n",
-       "host_name                            8\n",
-       "neighbourhood_group                  0\n",
-       "neighbourhood                        0\n",
-       "latitude                             0\n",
-       "longitude                            0\n",
-       "room_type                            0\n",
-       "price                                0\n",
-       "minimum_nights                       0\n",
-       "number_of_reviews                    0\n",
-       "last_review                       4123\n",
-       "reviews_per_month                 4123\n",
-       "calculated_host_listings_count       0\n",
-       "availability_365                     0\n",
-       "dtype: int64"
-      ]
-     },
-     "execution_count": 7,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "df.isnull().sum()"
-   ]
-  },
-  {
-   "cell_type": "markdown",
-   "id": "f1cc5d9a",
+   "execution_count": null,
+   "id": "1e0e121e",
    "metadata": {},
+   "outputs": [],
    "source": [
-    "#### Comment \n",
-    "* The sample consists of 20000 rows and 15 columns\n",
-    "* Four columns have null values, i.e. *name*, *host_name*, *last_review*, *reviews_per_month*.\n",
-    "* In particular *last_review* and *reviews_per_month* have the same number of NaNs. We can check whether they are related to the same listing, and if each listing has a *number_of_reviews* equal to 0. (**Assumption 1**)\n",
-    "* The following columns are of dtype *str*:\n",
-    "    - *name*\n",
-    "    - *host_name*\n",
-    "    - *neighbourhood_group*\n",
-    "    - *neighbourhood*\n",
-    "    - *room_type*\n",
-    "    - *last_review* -> this one could be further formatted in type timestamp \n",
-    "* Based on the low cardinality, some of these features can be considered categorical:\n",
-    "    - *neighbourhood*\n",
-    "    - *room_type*\n",
-    "* The remaining features are numerical, either integers or floating numbers"
+    "data = df.copy()\n",
+    "data.pop('price')\n",
+    "# extract number of features \n",
+    "n_features = data.columns.shape[0]\n",
+    "# identify numerical and categorical features\n",
+    "\n",
+    "# use the selector to get the categorical data\n",
+    "categorical_selector = selector(dtype_include =object)\n",
+    "numerical_selector = selector(dtype_exclude =object)\n",
+    "\n",
+    "# select the data based on the selector\n",
+    "categorical_data = data[categorical_selector(data)]\n",
+    "numerical_data = data[numerical_selector(data)]\n",
+    "\n",
+    "print(f'''\n",
+    "The dataset contains {n_features} features.\n",
+    "Numeric: {numerical_data.shape[1]} \n",
+    "Categorical: {categorical_data.shape[1]}.\n",
+    "''')"
    ]
   },
   {
    "cell_type": "markdown",
-   "id": "c8ab2738",
+   "id": "12e87b8d",
    "metadata": {},
    "source": [
-    "#### Testing Assumption 1"
+    "# Feature & target distribution overview"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
-   "id": "84a59d27",
+   "execution_count": null,
+   "id": "69143042",
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/html": [
-       "<div>\n",
-       "<style scoped>\n",
-       "    .dataframe tbody tr th:only-of-type {\n",
-       "        vertical-align: middle;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe tbody tr th {\n",
-       "        vertical-align: top;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe thead th {\n",
-       "        text-align: right;\n",
-       "    }\n",
-       "</style>\n",
-       "<table border=\"1\" class=\"dataframe\">\n",
-       "  <thead>\n",
-       "    <tr style=\"text-align: right;\">\n",
-       "      <th></th>\n",
-       "      <th>number_of_reviews</th>\n",
-       "      <th>last_review</th>\n",
-       "      <th>reviews_per_month</th>\n",
-       "    </tr>\n",
-       "  </thead>\n",
-       "  <tbody>\n",
-       "    <tr>\n",
-       "      <th>1</th>\n",
-       "      <td>0</td>\n",
-       "      <td>NaN</td>\n",
-       "      <td>NaN</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>10</th>\n",
-       "      <td>0</td>\n",
-       "      <td>NaN</td>\n",
-       "      <td>NaN</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>15</th>\n",
-       "      <td>0</td>\n",
-       "      <td>NaN</td>\n",
-       "      <td>NaN</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>16</th>\n",
-       "      <td>0</td>\n",
-       "      <td>NaN</td>\n",
-       "      <td>NaN</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>27</th>\n",
-       "      <td>0</td>\n",
-       "      <td>NaN</td>\n",
-       "      <td>NaN</td>\n",
-       "    </tr>\n",
-       "  </tbody>\n",
-       "</table>\n",
-       "</div>"
-      ],
-      "text/plain": [
-       "    number_of_reviews last_review  reviews_per_month\n",
-       "1                   0         NaN                NaN\n",
-       "10                  0         NaN                NaN\n",
-       "15                  0         NaN                NaN\n",
-       "16                  0         NaN                NaN\n",
-       "27                  0         NaN                NaN"
-      ]
-     },
-     "execution_count": 8,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
-    "subset = df[df['last_review'].isnull()][['number_of_reviews','last_review', 'reviews_per_month']]\n",
-    "subset.head()"
+    "_ = numerical_data.hist(figsize=(20, 14))"
    ]
   },
   {
-   "cell_type": "code",
-   "execution_count": 9,
-   "id": "b440b035",
+   "cell_type": "markdown",
+   "id": "e1d63bbd",
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "number_of_reviews      0\n",
-       "last_review            0\n",
-       "reviews_per_month    0.0\n",
-       "dtype: object"
-      ]
-     },
-     "execution_count": 9,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
    "source": [
-    "subset.sum()"
+    "The latitude and longitude features are the ones that seem to follow a Gaussian distribution. The other features as well as the target are skewed. Importantly, the ranges of the features can differ by orders of magnitude. This implies that scaling of the data is essential. "
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
-   "id": "d621bd2a",
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "number_of_reviews       0\n",
-       "last_review          4123\n",
-       "reviews_per_month    4123\n",
-       "dtype: int64"
-      ]
-     },
-     "execution_count": 10,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "subset.isnull().sum()"
-   ]
-  },
-  {
-   "cell_type": "markdown",
-   "id": "a1fa4758",
+   "execution_count": null,
+   "id": "6b0770ae",
    "metadata": {},
+   "outputs": [],
    "source": [
-    "#### Comment \n",
-    "**Assumption 1** is validated!\n",
-    "Features *last_review* and *reviews_per_month* are both NaNs when the *number_of_reviews* is equal to 0. It makes sense, as no reviews implies that no date the *last_review* can be retrieved and the calculation that output *reviews_per_month* cannot be computed."
+    "# overview of categorical data\n",
+    "[categorical_data[i].value_counts() for i in categorical_data.columns] "
    ]
   },
   {
    "cell_type": "markdown",
-   "id": "56d81a0d",
+   "id": "cd83bb75",
    "metadata": {},
    "source": [
-    "### Statistical description of the sample "
+    "We observe a similar behavior for the categorical features (heavily skewded data distributions)"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 11,
-   "id": "67f7819a",
+   "execution_count": null,
+   "id": "79f0555e",
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/html": [
-       "<div>\n",
-       "<style scoped>\n",
-       "    .dataframe tbody tr th:only-of-type {\n",
-       "        vertical-align: middle;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe tbody tr th {\n",
-       "        vertical-align: top;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe thead th {\n",
-       "        text-align: right;\n",
-       "    }\n",
-       "</style>\n",
-       "<table border=\"1\" class=\"dataframe\">\n",
-       "  <thead>\n",
-       "    <tr style=\"text-align: right;\">\n",
-       "      <th></th>\n",
-       "      <th>id</th>\n",
-       "      <th>host_id</th>\n",
-       "      <th>latitude</th>\n",
-       "      <th>longitude</th>\n",
-       "      <th>price</th>\n",
-       "      <th>minimum_nights</th>\n",
-       "      <th>number_of_reviews</th>\n",
-       "      <th>reviews_per_month</th>\n",
-       "      <th>calculated_host_listings_count</th>\n",
-       "      <th>availability_365</th>\n",
-       "    </tr>\n",
-       "  </thead>\n",
-       "  <tbody>\n",
-       "    <tr>\n",
-       "      <th>count</th>\n",
-       "      <td>2.000000e+04</td>\n",
-       "      <td>2.000000e+04</td>\n",
-       "      <td>20000.000000</td>\n",
-       "      <td>20000.000000</td>\n",
-       "      <td>20000.000000</td>\n",
-       "      <td>20000.000000</td>\n",
-       "      <td>20000.000000</td>\n",
-       "      <td>15877.000000</td>\n",
-       "      <td>20000.000000</td>\n",
-       "      <td>20000.000000</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>mean</th>\n",
-       "      <td>1.892380e+07</td>\n",
-       "      <td>6.746034e+07</td>\n",
-       "      <td>40.728455</td>\n",
-       "      <td>-73.952125</td>\n",
-       "      <td>153.269050</td>\n",
-       "      <td>6.992100</td>\n",
-       "      <td>23.274100</td>\n",
-       "      <td>1.377446</td>\n",
-       "      <td>6.955450</td>\n",
-       "      <td>112.901200</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>std</th>\n",
-       "      <td>1.101223e+07</td>\n",
-       "      <td>7.857936e+07</td>\n",
-       "      <td>0.054755</td>\n",
-       "      <td>0.046559</td>\n",
-       "      <td>243.325609</td>\n",
-       "      <td>21.645449</td>\n",
-       "      <td>44.927793</td>\n",
-       "      <td>1.683006</td>\n",
-       "      <td>32.433831</td>\n",
-       "      <td>131.762226</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>min</th>\n",
-       "      <td>2.539000e+03</td>\n",
-       "      <td>2.571000e+03</td>\n",
-       "      <td>40.508730</td>\n",
-       "      <td>-74.239140</td>\n",
-       "      <td>0.000000</td>\n",
-       "      <td>1.000000</td>\n",
-       "      <td>0.000000</td>\n",
-       "      <td>0.010000</td>\n",
-       "      <td>1.000000</td>\n",
-       "      <td>0.000000</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>25%</th>\n",
-       "      <td>9.393540e+06</td>\n",
-       "      <td>7.853718e+06</td>\n",
-       "      <td>40.689420</td>\n",
-       "      <td>-73.983030</td>\n",
-       "      <td>69.000000</td>\n",
-       "      <td>1.000000</td>\n",
-       "      <td>1.000000</td>\n",
-       "      <td>0.190000</td>\n",
-       "      <td>1.000000</td>\n",
-       "      <td>0.000000</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>50%</th>\n",
-       "      <td>1.952117e+07</td>\n",
-       "      <td>3.111431e+07</td>\n",
-       "      <td>40.722730</td>\n",
-       "      <td>-73.955640</td>\n",
-       "      <td>105.000000</td>\n",
-       "      <td>2.000000</td>\n",
-       "      <td>5.000000</td>\n",
-       "      <td>0.720000</td>\n",
-       "      <td>1.000000</td>\n",
-       "      <td>44.000000</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>75%</th>\n",
-       "      <td>2.912936e+07</td>\n",
-       "      <td>1.068426e+08</td>\n",
-       "      <td>40.762990</td>\n",
-       "      <td>-73.936380</td>\n",
-       "      <td>175.000000</td>\n",
-       "      <td>5.000000</td>\n",
-       "      <td>23.000000</td>\n",
-       "      <td>2.010000</td>\n",
-       "      <td>2.000000</td>\n",
-       "      <td>229.000000</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>max</th>\n",
-       "      <td>3.648561e+07</td>\n",
-       "      <td>2.742733e+08</td>\n",
-       "      <td>40.913060</td>\n",
-       "      <td>-73.717950</td>\n",
-       "      <td>10000.000000</td>\n",
-       "      <td>1250.000000</td>\n",
-       "      <td>607.000000</td>\n",
-       "      <td>27.950000</td>\n",
-       "      <td>327.000000</td>\n",
-       "      <td>365.000000</td>\n",
-       "    </tr>\n",
-       "  </tbody>\n",
-       "</table>\n",
-       "</div>"
-      ],
-      "text/plain": [
-       "                 id       host_id      latitude     longitude         price  \\\n",
-       "count  2.000000e+04  2.000000e+04  20000.000000  20000.000000  20000.000000   \n",
-       "mean   1.892380e+07  6.746034e+07     40.728455    -73.952125    153.269050   \n",
-       "std    1.101223e+07  7.857936e+07      0.054755      0.046559    243.325609   \n",
-       "min    2.539000e+03  2.571000e+03     40.508730    -74.239140      0.000000   \n",
-       "25%    9.393540e+06  7.853718e+06     40.689420    -73.983030     69.000000   \n",
-       "50%    1.952117e+07  3.111431e+07     40.722730    -73.955640    105.000000   \n",
-       "75%    2.912936e+07  1.068426e+08     40.762990    -73.936380    175.000000   \n",
-       "max    3.648561e+07  2.742733e+08     40.913060    -73.717950  10000.000000   \n",
-       "\n",
-       "       minimum_nights  number_of_reviews  reviews_per_month  \\\n",
-       "count    20000.000000       20000.000000       15877.000000   \n",
-       "mean         6.992100          23.274100           1.377446   \n",
-       "std         21.645449          44.927793           1.683006   \n",
-       "min          1.000000           0.000000           0.010000   \n",
-       "25%          1.000000           1.000000           0.190000   \n",
-       "50%          2.000000           5.000000           0.720000   \n",
-       "75%          5.000000          23.000000           2.010000   \n",
-       "max       1250.000000         607.000000          27.950000   \n",
-       "\n",
-       "       calculated_host_listings_count  availability_365  \n",
-       "count                    20000.000000      20000.000000  \n",
-       "mean                         6.955450        112.901200  \n",
-       "std                         32.433831        131.762226  \n",
-       "min                          1.000000          0.000000  \n",
-       "25%                          1.000000          0.000000  \n",
-       "50%                          1.000000         44.000000  \n",
-       "75%                          2.000000        229.000000  \n",
-       "max                        327.000000        365.000000  "
-      ]
-     },
-     "execution_count": 11,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
-    "df.describe()"
+    "nan_perc = df.isnull().mean() * 100\n",
+    "nan_perc.plot(kind='bar')"
    ]
   },
   {
    "cell_type": "markdown",
-   "id": "79909bc5",
+   "id": "3cc628c7",
    "metadata": {},
    "source": [
-    "#### Comment \n",
-    "* Comparing the percentile values and the max values, some features seem to have outliers. In particular:\n",
-    "    - *price*\n",
-    "    - *minimum_nights*\n",
-    "    - *number_of_reviews*\n",
-    "    - *reviews_per_month*\n",
-    "    - *calculated_host_listings_count*\n",
-    "* This observation calls for further investigation "
+    "We observe that the features \"last_review\" and \"reviews_per_month\" have around 20% of missing data. This is still within the percentage region that allows for data imputation. We therefore, decide to keep these features in the feature matrix. "
    ]
   },
   {
@@ -773,7 +194,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 12,
+   "execution_count": null,
    "id": "e65f27c1",
    "metadata": {
     "scrolled": true
@@ -785,7 +206,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 13,
+   "execution_count": null,
    "id": "343494cd",
    "metadata": {},
    "outputs": [],
@@ -798,22 +219,7 @@
    "execution_count": null,
    "id": "c1a0f138",
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "a9b82a6a5f404d9981d8bc0d069fb45a",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    }
-   ],
+   "outputs": [],
    "source": [
     "profile"
    ]
@@ -824,70 +230,11 @@
    "metadata": {},
    "source": [
     "#### Comments\n",
-    "* Many of the observations found above are also validated in the report.\n",
-    "* Variables:\n",
-    "    - *number_of_reviews* and *availability_365* have many zeroes\n",
-    "* Most interesting correlations:\n",
-    "    - *price* is inversely correlated to *longitude* but not so much with *latitude*\n",
-    "    - *number_of_reviews* is highly correlated to *reviews_per_month* as one could expect\n",
-    "    - *availability_365* is loosely and positevely correlated to *reviews*, *reviews_per_month* and *calculated_host_listings_count*"
-   ]
-  },
-  {
-   "cell_type": "markdown",
-   "id": "9a26e088",
-   "metadata": {},
-   "source": [
-    "### Fix problems"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "id": "270c4e5b",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "# Drop outliers\n",
-    "min_price = 10\n",
-    "max_price = 350\n",
-    "min_nights= 1 \n",
-    "max_nights= 365\n",
-    "idx = df['price'].between(min_price, max_price)\n",
-    "df = df[idx].copy()\n",
-    "idx = df['minimum_nights'].between(min_nightshts, max_nights)\n",
-    "df = df[idx].copy()\n",
-    "# Convert last_review to datetime\n",
-    "df['last_review'] = pd.to_datetime(df['last_review'])"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "id": "e6eb2c5b",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "df.describe()"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "id": "e15fd106",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "df.info()"
-   ]
-  },
-  {
-   "cell_type": "markdown",
-   "id": "2d6973f6",
-   "metadata": {},
-   "source": [
-    "#### Comments\n",
-    "* We can confirm that cleaning steps were successfully performed  "
+    "* Our initial observations are validated by the report.\n",
+    "* The room_type \"Shared room\" is the minority class in this category\n",
+    "* The availability_365 feature has a high percentage of zero-values which skew the distribution to the right.\n",
+    "* host_id and id features are highly correlated, therefore, one feature must be dropped\n",
+    "* Reviews and 'number_of_reviews| are also highly correlated"
    ]
   },
   {
@@ -907,14 +254,6 @@
    "source": [
     "run.finish()"
    ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "id": "9e893ca2",
-   "metadata": {},
-   "outputs": [],
-   "source": []
   }
  ],
  "metadata": {
@@ -933,7 +272,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.9.12"
+   "version": "3.10.8"
   }
  },
  "nbformat": 4,
diff --git a/src/eda/conda.yml b/src/eda/conda.yml
index 64eb11f..66a23bf 100644
--- a/src/eda/conda.yml
+++ b/src/eda/conda.yml
@@ -3,11 +3,12 @@ channels:
   - conda-forge
   - defaults
 dependencies:
-  - jupyterlab=3.0.12
-  - seaborn=0.11.1
-  - pandas=1.2.3
+  - scikit-learn 
+  - jupyterlab
+  - notebook
+  - pandas=1.5.2
   - pip=20.3.3
-  - pandas-profiling=3.1.0
+  - pandas-profiling
   - pyarrow=2.0
   - pip:
       - wandb==0.13.5
diff --git a/src/train_random_forest/feature_engineering.py b/src/train_random_forest/feature_engineering.py
deleted file mode 100644
index d4a1c73..0000000
--- a/src/train_random_forest/feature_engineering.py
+++ /dev/null
@@ -1,11 +0,0 @@
-import pandas as pd
-import numpy as np
-
-
-def delta_date_feature(dates):
-    """
-    Given a 2d array containing dates (in any format recognized by pd.to_datetime), it returns the delta in days
-    between each date and the most recent date in its column
-    """
-    date_sanitized = pd.DataFrame(dates).apply(pd.to_datetime)
-    return date_sanitized.apply(lambda d: (d.max() -d).dt.days, axis=0).to_numpy()
diff --git a/src/train_random_forest/run.py b/src/train_random_forest/run.py
index c3999ad..1fdf0bf 100644
--- a/src/train_random_forest/run.py
+++ b/src/train_random_forest/run.py
@@ -2,6 +2,9 @@
 """
 This script trains a Random Forest
 """
+# =============================================================================
+# MODULES
+# =============================================================================
 import argparse
 import logging
 import os
@@ -26,18 +29,25 @@ from sklearn.metrics import mean_absolute_error
 from sklearn.pipeline import Pipeline, make_pipeline
 
 
+# =============================================================================
+# FEATURE ENGINEERING
+# =============================================================================
 def delta_date_feature(dates):
     """
     Given a 2d array containing dates (in any format recognized by pd.to_datetime), it returns the delta in days
     between each date and the most recent date in its column
     """
     date_sanitized = pd.DataFrame(dates).apply(pd.to_datetime)
-    return date_sanitized.apply(lambda d: (d.max() -d).dt.days, axis=0).to_numpy()
+    return date_sanitized.apply(lambda d: (d.max() - d).dt.days, axis=0).to_numpy()
 
 
 logging.basicConfig(level=logging.INFO, format="%(asctime)-15s %(message)s")
 logger = logging.getLogger()
 
+# =============================================================================
+# MAIN
+# =============================================================================
+
 
 def go(args):
 
@@ -52,11 +62,12 @@ def go(args):
     # Fix the random seed for the Random Forest, so we get reproducible results
     rf_config['random_state'] = args.random_seed
 
-     # Get artifact and save file in train_local_path
+    # Get artifact and save file in train_local_path
     trainval_local_path = run.use_artifact(args.trainval_artifact).file()
 
     X = pd.read_csv(trainval_local_path)
-    y = X.pop("price")  # this removes the column "price" from X and puts it into y
+    # this removes the column "price" from X and puts it into y
+    y = X.pop("price")
 
     logger.info(f"Minimum price: {y.min()}, Maximum price: {y.max()}")
 
@@ -66,12 +77,13 @@ def go(args):
 
     logger.info("Preparing sklearn pipeline")
 
-    sk_pipe, processed_features = get_inference_pipeline(rf_config, args.max_tfidf_features)
+    sk_pipe, processed_features = get_inference_pipeline(
+        rf_config, args.max_tfidf_features)
 
     # Then fit it to the X_train, y_train data
     logger.info("Fitting")
 
-    # Fit the pipeline sk_pipe 
+    # Fit the pipeline sk_pipe
     sk_pipe.fit(X_train, y_train)
 
     # Compute r2 and MAE
@@ -92,12 +104,12 @@ def go(args):
 
     # Infer the signature of the model
     signature = infer_signature(X_val, y_pred)
-    
+
     # Save the sk_pipe pipeline
     mlflow.sklearn.save_model(sk_pipe,
-                                "random_forest_dir", 
-                                signature=signature,
-                                input_example=X_val.iloc[:2])
+                              "random_forest_dir",
+                              signature=signature,
+                              input_example=X_val.iloc[:2])
 
     # Create and log W&B artifact
     artifact = wandb.Artifact(
@@ -121,21 +133,27 @@ def go(args):
     # Upload to W&B the feture importance visualization
     run.log(
         {
-          "feature_importance": wandb.Image(fig_feat_imp),
+            "feature_importance": wandb.Image(fig_feat_imp),
         }
     )
 
+# =============================================================================
+# FEATURE IMPORTANCE
+# =============================================================================
+
 
 def plot_feature_importance(pipe, feat_names):
     # We collect the feature importance for all non-nlp features first
     feat_imp = pipe["random_forest"].feature_importances_[: len(feat_names)-1]
     # For the NLP feature we sum across all the TF-IDF dimensions into a global
     # NLP importance
-    nlp_importance = sum(pipe["random_forest"].feature_importances_[len(feat_names) - 1:])
+    nlp_importance = sum(pipe["random_forest"].feature_importances_[
+                         len(feat_names) - 1:])
     feat_imp = np.append(feat_imp, nlp_importance)
     fig_feat_imp, sub_feat_imp = plt.subplots(figsize=(10, 10))
     # idx = np.argsort(feat_imp)[::-1]
-    sub_feat_imp.bar(range(feat_imp.shape[0]), feat_imp, color="r", align="center")
+    sub_feat_imp.bar(
+        range(feat_imp.shape[0]), feat_imp, color="r", align="center")
     _ = sub_feat_imp.set_xticks(range(feat_imp.shape[0]))
     _ = sub_feat_imp.set_xticklabels(np.array(feat_names), rotation=90)
     fig_feat_imp.tight_layout()
@@ -161,7 +179,7 @@ def get_inference_pipeline(rf_config, max_tfidf_features):
         SimpleImputer(strategy="most_frequent"),
         OneHotEncoder()
     )
-    
+
     # Let's impute the numerical columns to make sure we can handle missing values
     # (note that we do not scale because the RF algorithm does not need that)
     zero_imputed = [
@@ -181,7 +199,8 @@ def get_inference_pipeline(rf_config, max_tfidf_features):
     # a review for a long time), and then we create a new feature from it,
     date_imputer = make_pipeline(
         SimpleImputer(strategy='constant', fill_value='2010-01-01'),
-        FunctionTransformer(delta_date_feature, check_inverse=False, validate=False)
+        FunctionTransformer(delta_date_feature,
+                            check_inverse=False, validate=False)
     )
 
     # Some minimal NLP for the "name" column
@@ -200,7 +219,8 @@ def get_inference_pipeline(rf_config, max_tfidf_features):
     preprocessor = ColumnTransformer(
         transformers=[
             ("ordinal_cat", ordinal_categorical_preproc, ordinal_categorical),
-            ("non_ordinal_cat", non_ordinal_categorical_preproc, non_ordinal_categorical),
+            ("non_ordinal_cat", non_ordinal_categorical_preproc,
+             non_ordinal_categorical),
             ("impute_zero", zero_imputer, zero_imputed),
             ("transform_date", date_imputer, ["last_review"]),
             ("transform_name", name_tfidf, ["name"])
@@ -208,7 +228,8 @@ def get_inference_pipeline(rf_config, max_tfidf_features):
         remainder="drop",  # This drops the columns that we do not transform
     )
 
-    processed_features = ordinal_categorical + non_ordinal_categorical + zero_imputed + ["last_review", "name"]
+    processed_features = ordinal_categorical + \
+        non_ordinal_categorical + zero_imputed + ["last_review", "name"]
 
     # Create random forest
     random_Forest = RandomForestRegressor(**rf_config)
@@ -224,6 +245,9 @@ def get_inference_pipeline(rf_config, max_tfidf_features):
     return sk_pipe, processed_features
 
 
+# =============================================================================
+# CALL MAIN
+# =============================================================================
 if __name__ == "__main__":
 
     parser = argparse.ArgumentParser(description="Basic cleaning of dataset")
